{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language (ASL) recognition\n",
    "An Artificial Intelligence project by Emile GATIGNON and Martin RAMPONT\n",
    "\n",
    "> \"Artificial Intelligence\" - Course N° 12721 at Hanyang University with professor 백성용 / Sungyong Baik\n",
    "> \n",
    "> Spring Semester 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs\n",
    "%pip install opencv-python mediapipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import cv2\n",
    "import hashlib\n",
    "import json\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "\n",
    "# Dataset\n",
    "# ? Dataset source : https://www.kaggle.com/datasets/risangbaskoro/wlasl-processed\n",
    "data_url = r'https://storage.googleapis.com/kaggle-data-sets/1589971/2632847/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230528%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230528T101545Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=3d32a329ea1d2da65583832ef994b2b0ada5e17e04f938afff9fdd04fca8643b22b889accfc807458f1f8616b28cc2b0412f464649c851bdd2d0d6d4bfca08bd85f37f0be1653fdd3c85fb44b6abf81faf3051ca1eb817c1a52158574d1545d7723f498008fb2b151c5a1a2ab855299e72727c9ecc3138965c81e33660024625a3779e065613c78c7520913c5279bdbe392010d66bab023509f1a1a792fb5567ddf7865fdb51f354fd737ac202a07d02481ec04eb5e26f44a94aa942d4dd395bd1f5984ba5eb60b46a80a5cd33b7229558c69bfd524c3e7ec49b18150956e3b0b96849ec2270cadb458b38f9cee415722a91fbbecc3acebabec79d25016c0217'\n",
    "data_path = r'downloads/data'\n",
    "videos_folder = r'videos'\n",
    "landmarks_folder = r'landmarks'\n",
    "data_description_file = r'WLASL_v0.3.json'\n",
    "labels_file = r'labels.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset download and extraction\n",
    "data_zip_hash = '1b8198227bb3de21de639146016a7368'\n",
    "\n",
    "if os.path.isdir(os.path.join(data_path, landmarks_folder)):\n",
    "    print(\"Landmarks found, skipping download\")\n",
    "elif os.path.isfile(os.path.join(data_path, data_description_file)) \\\n",
    "        and os.path.isdir(os.path.join(data_path, videos_folder)):\n",
    "    print(\"Data already unpacked, skipping\")\n",
    "else:\n",
    "    downloaded_hash = ''\n",
    "    if os.path.isfile(data_path + '.zip'):\n",
    "        print(\"Data already downloaded, checking intergrity...\")\n",
    "        hash_md5 = hashlib.md5()\n",
    "        with open(data_path + '.zip', \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                hash_md5.update(chunk)\n",
    "        downloaded_hash = hash_md5.hexdigest()\n",
    "\n",
    "    if data_zip_hash != downloaded_hash:\n",
    "        def report_hook(count, block_size, total_size):\n",
    "            percentage = (count * block_size / total_size) * 100\n",
    "            print(f\"Downloading data... {percentage:.2f}%\", end='\\r')\n",
    "        urllib.request.urlretrieve(data_url, data_path + '.zip', reporthook=report_hook)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(\"Downloaded zip integrity ok\")\n",
    "\n",
    "    with zipfile.ZipFile(data_path + '.zip', 'r') as zip_ref:\n",
    "        total_files = len(zip_ref.namelist())\n",
    "        extracted_files = 0\n",
    "        for file in zip_ref.namelist():\n",
    "            zip_ref.extract(file, data_path)\n",
    "\n",
    "            extracted_files += 1\n",
    "            progress = (extracted_files / total_files) * 100\n",
    "            print(f\"Extracting... {progress:.2f}%\", end='\\r')\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landmark detection - variables and functions\n",
    "\n",
    "MP_HOLISTIC = mp.solutions.holistic\n",
    "MP_DRAWING = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "def mediapipe_detection(image: cv2.Mat, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    MP_DRAWING.draw_landmarks(image, results.face_landmarks, MP_HOLISTIC.FACEMESH_CONTOURS,\n",
    "                              MP_DRAWING.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                              MP_DRAWING.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1)\n",
    "                              )\n",
    "    # Draw pose connections\n",
    "    MP_DRAWING.draw_landmarks(image, results.pose_landmarks, MP_HOLISTIC.POSE_CONNECTIONS,\n",
    "                              MP_DRAWING.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                              MP_DRAWING.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "    # Draw left hand connections\n",
    "    MP_DRAWING.draw_landmarks(image, results.left_hand_landmarks, MP_HOLISTIC.HAND_CONNECTIONS,\n",
    "                              MP_DRAWING.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                              MP_DRAWING.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "    # Draw right hand connections\n",
    "    MP_DRAWING.draw_landmarks(image, results.right_hand_landmarks, MP_HOLISTIC.HAND_CONNECTIONS,\n",
    "                              MP_DRAWING.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                              MP_DRAWING.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                              )\n",
    "\n",
    "\n",
    "def extract_landmarks(results) -> np.ndarray:\n",
    "    \"\"\"Transforms the results from a mediapipe process to a NumPy Array\n",
    "\n",
    "    Args:\n",
    "        results: Results from a mediapipe process\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Vectorized results, missing landmarks are representend as numpy.nan\n",
    "\n",
    "        results.shape = (4,)\n",
    "\n",
    "        results[0].shape = (468, 3), results[1].shape = (33, 3),\n",
    "        results[2].shape = (21, 3), results[3].shape = (21, 3)\n",
    "    \"\"\"\n",
    "    face_landmarks = np.zeros((468, 3))\n",
    "    face_landmarks.fill(np.nan)\n",
    "    if results.face_landmarks != None:\n",
    "        for i, landmark in enumerate(results.face_landmarks.landmark):\n",
    "            face_landmarks[i] = landmark.x, landmark.y, landmark.z\n",
    "    else:\n",
    "        face_landmarks.fill(np.nan)\n",
    "\n",
    "    pose_landmarks = np.zeros((33, 3))\n",
    "    pose_landmarks.fill(np.nan)\n",
    "    if results.pose_landmarks != None:\n",
    "        for i, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "            pose_landmarks[i] = landmark.x, landmark.y, landmark.z\n",
    "    else:\n",
    "        pose_landmarks.fill(np.nan)\n",
    "\n",
    "    left_hand_landmarks = np.zeros((21, 3))\n",
    "    left_hand_landmarks.fill(np.nan)\n",
    "    if results.left_hand_landmarks != None:\n",
    "        for i, landmark in enumerate(results.left_hand_landmarks.landmark):\n",
    "            left_hand_landmarks[i] = landmark.x, landmark.y, landmark.z\n",
    "    else:\n",
    "        left_hand_landmarks.fill(np.nan)\n",
    "\n",
    "    right_hand_landmarks = np.zeros((21, 3))\n",
    "    right_hand_landmarks.fill(np.nan)\n",
    "    if results.right_hand_landmarks != None:\n",
    "        for i, landmark in enumerate(results.right_hand_landmarks.landmark):\n",
    "            right_hand_landmarks[i] = landmark.x, landmark.y, landmark.z\n",
    "    else:\n",
    "        right_hand_landmarks.fill(np.nan)\n",
    "\n",
    "    return np.array([face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks], dtype=object)\n",
    "\n",
    "\n",
    "def video_to_landmarks(video_path: str, display: bool = False) -> np.ndarray:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    landmark_frames = np.zeros((int(cap.get(cv2.CAP_PROP_FRAME_COUNT))), dtype=np.ndarray)\n",
    "    i = 0\n",
    "    with MP_HOLISTIC.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "            landmark_frames[i] = extract_landmarks(results)\n",
    "            i += 1\n",
    "\n",
    "            if display:\n",
    "                draw_styled_landmarks(image, results)\n",
    "                cv2.imshow(f\"Converting '{video_path}'...\", image)\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    display = False\n",
    "                    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return landmark_frames, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landmark detection - dataset conversion\n",
    "display_conversion = False\n",
    "videos_path = os.path.join(data_path, videos_folder)\n",
    "landmarks_path = os.path.join(data_path, landmarks_folder)\n",
    "\n",
    "\n",
    "if not os.path.exists(landmarks_path):\n",
    "    os.mkdir(landmarks_path)\n",
    "video_count = len(os.listdir(videos_path))\n",
    "skipped = 0\n",
    "\n",
    "try:\n",
    "    for i, video_path in enumerate(os.listdir(videos_path)):\n",
    "        progress = 100 * i / video_count\n",
    "        print(f\"Generating landmarks: {progress:6.2f}% ({skipped:5} skipped) -> {video_path}\", end='\\r')\n",
    "\n",
    "        array_path = os.path.join(landmarks_path, video_path[:-4]) + '.npy'\n",
    "        if video_path.endswith('.mp4') and not os.path.isfile(array_path):\n",
    "            landmarks, display_conversion = video_to_landmarks(os.path.join(videos_path, video_path), display_conversion)\n",
    "            np.save(array_path, landmarks)\n",
    "        else:\n",
    "            skipped += 1\n",
    "except KeyboardInterrupt:\n",
    "    count = len(os.listdir(landmarks_path))\n",
    "    progress = 100 * count / video_count\n",
    "    print(f\"Interrupted landmark generation at {progress:6.2f}% -> {skipped} skipped, {count - skipped} generated\")\n",
    "print(f\"Finished landmark generation -> {skipped} skipped, {len(os.listdir(landmarks_path)) - skipped} generated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels extraction\n",
    "\n",
    "if os.path.isfile(os.path.join(data_path, labels_file)):\n",
    "    print(\"Labels already generated, skipping\")\n",
    "else:\n",
    "    labels = {}\n",
    "\n",
    "    print(\"Loading data description and extracting labels...\")\n",
    "    with open(os.path.join(data_path, data_description_file), \"r\") as data_descriptor:\n",
    "        data_desc = json.load(data_descriptor)\n",
    "        for entry in data_desc:\n",
    "            for instance in entry['instances']:\n",
    "                labels[instance['video_id']] = entry['gloss']\n",
    "\n",
    "    print(\"Saving labels...\")\n",
    "    with open(os.path.join(data_path, labels_file), \"w\") as labels_container:\n",
    "        json.dump(labels, labels_container, indent=4)\n",
    "\n",
    "    print(\"Labels generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
